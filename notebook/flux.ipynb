{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2507d149-dcab-458a-a554-37388e0ee13a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div>\n",
    "<center><img src=\"Flux-logo.svg\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e867ba-f689-4301-bb60-9a448556bb84",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Flux RADIUSS Tutorial on AWS\n",
    "\n",
    "> What is Flux Framework? ü§îÔ∏è\n",
    " \n",
    "Flux is a flexible framework for resource management, built for your site. The framework consists of a suite of projects, tools, and libraries which may be used to build site-custom resource managers for High Performance Computing centers. Flux is a next-generation resource manager and scheduler with many transformative capabilities like hierarchical scheduling and resource management (you can think of it as \"fractal scheduling\") and directed-graph based resource representations.\n",
    "\n",
    "> I'm ready! How do I do this tutorial? üòÅÔ∏è\n",
    "\n",
    "To step through examples in this notebook you need to execute cells. To run a cell, press Shift+Enter on your keyboard. If you prefer, you can also paste the shell commands in the JupyterLab terminal and execute them there.\n",
    "Let's get started! To provide some brief, added background on Flux and a bit more motivation for our tutorial, \"Shift+Enter\" the cell below to watch our YouTube video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ecd22-8552-4b4d-9bc4-61d86f8d33fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe width=\"640\" height=\"360\" \n",
    "    src=\"https://www.youtube.com/embed/YIwt51dyXOE\" \n",
    "    title=\"YouTube video player\" \n",
    "    frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" \n",
    "    allowfullscreen>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e82c38-8465-49ac-ae2b-b0bb56a79ec9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Getting started with Flux\n",
    "\n",
    "The code and examples that this tutorial is based on can be found at [flux-framework/Tutorials](https://github.com/flux-framework/Tutorials/tree/master/2023-RADIUSS-AWS). You can also find the examples one level up in the flux-workflow-examples directory in this JupyterLab instance.\n",
    "\n",
    "## Resources\n",
    "\n",
    "> Looking for other resources? We got you covered! ü§ìÔ∏è\n",
    "\n",
    " - [https://flux-framework.org/](https://flux-framework.org/) Flux Framework portal for projects, releases, and publication.\n",
    " - [Flux Documentation](https://flux-framework.readthedocs.io/en/latest/).\n",
    " - [Flux Framework Cheat Sheet](https://flux-framework.org/cheat-sheet/)\n",
    " - [Flux Glossary of Terms](https://flux-framework.readthedocs.io/en/latest/glossary.html)\n",
    " - [Flux Comics](https://flux-framework.readthedocs.io/en/latest/comics/fluxonomicon.html) come and meet FluxBird - the pink bird who knows things!\n",
    " - [Flux Learning Guide](https://flux-framework.readthedocs.io/en/latest/guides/learning_guide.html) learn about what Flux does, how it works, and real research applications \n",
    " - [Getting Started with Flux and Go](https://converged-computing.github.io/flux-go/)\n",
    " - [Getting Started with Flux in C](https://converged-computing.github.io/flux-c-examples/) *looking for contributors*\n",
    "\n",
    "To read the Flux manpages and get help, run `flux help`. To get documentation on a subcommand, run, e.g. `flux help config`.  Here is an example of running `flux help` right from the notebook. Yes, did you know we are running in a Flux Instance right now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d616de-70cd-4090-bd43-ffacb5ade1f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!flux help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae33fef6-278c-4996-8534-fd15e548b338",
   "metadata": {
    "tags": []
   },
   "source": [
    "Did you know you can also get help for a specific command? For example, let's run, e.g. `flux help jobs` to get information on a sub-command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e54f640-283a-4523-8dde-9617fd6ef0c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#flux help jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e435d6-0927-4966-a4d7-47a128c94158",
   "metadata": {
    "tags": []
   },
   "source": [
    "### You can run any of the commands and examples that follow in the JupyterLab terminal. You can find the terminal in the JupyterLab launcher.\n",
    "If you do `File -> New -> Terminal` you can open a raw terminal to play with Flux. You'll see a prompt like this: \n",
    "\n",
    "`∆í(s=4,d=0) fluxuser@6e0f43fd90eb:~$`\n",
    "\n",
    "`s=4` indicates the number of running Flux brokers, `d=0` indicates the Flux hierarchy depth. `@6e0f43fd90eb` references the host, which is a Docker container for our tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e3df1d-32c9-4996-b6f7-2fa85f4c02ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating Flux Instances\n",
    "\n",
    "A Flux instance is a fully functional set of services which manage compute resources under its domain with the capability to launch jobs on those resources. A Flux instance may be running as the default resource manager on a cluster, a job in a resource manager such as Slurm, LSF, or Flux itself, or as a test instance launched locally.\n",
    "\n",
    "When run as a job in another resource manager, Flux is started like an MPI program, e.g., `srun [OPTIONS] flux start [SCRIPT]`. Flux is unique in that a test instance which mimics a multi-node instance can be started locally with simply `flux start --test-size=N`. This offers users to a way to learn and test interfaces and commands without access to an HPC cluster.\n",
    "\n",
    "To start a Flux session with 4 brokers in your container, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d568de50-f9e0-452f-8364-e52853013d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux start --test-size=4 flux getattr size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693f2d9-651f-4f58-bf53-62528caa83d9",
   "metadata": {},
   "source": [
    "The output indicates the number of brokers started successfully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1a33c-9f9e-4ba0-a013-e97601f79e41",
   "metadata": {},
   "source": [
    "## Flux uptime\n",
    "Flux provides an `uptime` utility to display properties of the Flux instance such as state of the current instance, how long it has been running, its size and if scheduling is disabled or stopped. The output shows how long the instance has been up, the instance owner, the instance depth (depth in the Flux hierarchy), and the size of the instance (number of brokers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6057ce25-d1b3-4cc6-b26a-4b05a1639616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!flux uptime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee2d6af-43fa-490e-88e9-10f13e660125",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Submitting Jobs to Flux\n",
    "## Submission CLI\n",
    "### `flux`: the Job Submission Tool\n",
    "\n",
    "To submit jobs to Flux, you can use the `flux` `submit`, `run`, `bulksubmit`, `batch`, and `alloc` commands.  The `flux submit` command submits a job to Flux and prints out the jobid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e7d41-1d8d-426c-8198-0ad4a57e7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux submit hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e4c25e-3ca8-4277-bb70-a0e94bcd223b",
   "metadata": {},
   "source": [
    "`submit` supports common options like `--nnodes`, `--ntasks`, and `--cores-per-task`. There are short option equivalents (`-N`, `-n`, and `-c`, respectively) of these options as well. `--cores-per-task=1` is the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d8c3d-b24a-415e-b9ac-f58b99a7e92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux submit -N1 -n2 sleep inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2bddee-f454-4674-80d4-4a39c5f1bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux submit --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac798095",
   "metadata": {},
   "source": [
    "The `flux run` command submits a job to Flux (similar to `flux submit`) but then attaches to the job with `flux job attach`, printing the job's stdout/stderr to the terminal and exiting with the same exit code as the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d26496-dd1f-44f7-bb10-8a9b4b8c9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux run hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53357a9d-11d8-4c2d-87d8-c30ae38d01ba",
   "metadata": {},
   "source": [
    "The output from the previous command is the hostname (a container ID string in this case). If the job exits with a non-zero exit code this will be reported by `flux job attach` (occurs implicitly with `flux run`). For example, execute the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa40cb98-a138-4771-a7ef-f1860dddf7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux run /bin/false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b5c3f-e24a-45a8-a10c-e10bfdbb7b87",
   "metadata": {},
   "source": [
    "A job submitted with `run` can be canceled with two rapid `Cltr-C`s in succession, or a user can detach from the job with `Ctrl-C Ctrl-Z`. The user can then re-attach to the job by using `flux job attach JOBID`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e5213d",
   "metadata": {},
   "source": [
    "`flux submit` and `flux run` also support many other useful flags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02032748",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux run -n4 --label-io --time-limit=5s --env-remove=LD_LIBRARY_PATH hostname\n",
    "!flux run --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e9ed6c",
   "metadata": {},
   "source": [
    "The `flux bulksubmit` command enqueues jobs based on a set of inputs which are substituted on the command line, similar to `xargs` and the GNU `parallel` utility, except the jobs have access to the resources of an entire Flux instance instead of only the local system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e82702",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux bulksubmit --watch --wait echo {} ::: foo bar baz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a8056-1661-4b76-9ca3-5e536c687e82",
   "metadata": {},
   "source": [
    "The `--cc` option to `submit` makes repeated submission even easier via, `flux submit --cc=IDSET`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1962b-1831-4bd2-8dab-c61fd710df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux submit --cc=1-10 --watch hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca3706-8bb4-4fd6-a37c-e6135fb05604",
   "metadata": {},
   "source": [
    "Try it in the JupyterLab terminal with a progress bar and jobs/s rate report: `flux submit --cc=1-100 --watch --progress --jps hostname`\n",
    "\n",
    "Note that `--wait` is implied by `--watch`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5a18ff-8d6a-47e9-a164-931ed1275ef4",
   "metadata": {},
   "source": [
    "Of course, Flux can launch more than just single-node, single-core jobs.  We can submit multiple heterogeneous jobs and Flux will co-schedule the jobs while also ensuring no oversubscription of resources (e.g., cores).\n",
    "\n",
    "Note: in this tutorial, we cannot assume that the host you are running on has multiple cores, thus the examples below only vary the number of nodes per job.  Varying the `cores-per-task` is also possible on Flux when the underlying hardware supports it (e.g., a multi-core node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux submit --nodes=2 --ntasks=2 --cores-per-task=1 --job-name simulation sleep inf\n",
    "!flux submit --nodes=1 --ntasks=1 --cores-per-task=1 --job-name analysis sleep inf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f446c-b2e8-40d8-b6bd-eb6b9dba3c71",
   "metadata": {},
   "source": [
    "### ‚≠êÔ∏è New Command Alert! `flux watch` ‚≠êÔ∏è\n",
    "\n",
    "Wouldn't it be cool to submit a job and then watch it? Well, yeah! We can do this now with flux watch. Let's run a fun example, and then watch the output. We have sleeps in here interspersed with echos only to show you the live action! ü•ûÔ∏è\n",
    "Also note a nice trick - you can always use `flux job last` to get the last JOBID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad231c2-4cdb-4d18-afc2-7cb3a74759c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux submit ../flux-workflow-examples/job-watch/job-watch.sh\n",
    "!flux watch $(flux job last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c2af2",
   "metadata": {},
   "source": [
    "### Listing job properties with `flux jobs`\n",
    "\n",
    "We can now list the jobs in the queue with `flux jobs` and we should see both jobs that we just submitted. Jobs that are instances are colored blue in output, red jobs are failed jobs, and green jobs are those that completed successfully. Note that the JupyterLab notebook may not display these colors. You will be able to see them in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca4277",
   "metadata": {},
   "source": [
    "Since those jobs won't ever exit (and we didn't specify a timelimit), let's kill them off now and free up the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd8ec8-6c64-4d8d-9a00-949f5f58c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux job killall -f\n",
    "!flux jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544aa0a9",
   "metadata": {},
   "source": [
    "We can use the `flux batch` command to easily created nested flux instances.  When `flux batch` is invoked, Flux will automatically create a nested instance that spans the resources allocated to the job, and then Flux runs the batch script passed to `flux batch` on rank 0 of the nested instance. \"Rank\" refers to the rank of the Tree-Based Overlay Network (TBON) used by the Flux brokers: https://flux-framework.readthedocs.io/projects/flux-core/en/latest/man1/flux-broker.html\n",
    "\n",
    "While a batch script is expected to launch parallel jobs using `flux run` or `flux submit` at this level, nothing prevents the script from further batching other sub-batch-jobs using the `flux batch` interface, if desired.\n",
    "\n",
    "Note: Flux also provides a `flux alloc` which is an interactive version of `flux batch`, but demonstrating that in a Jupyter notebook is difficult due to the lack of pseudo-terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux batch --nslots=2 --cores-per-slot=1 --nodes=2 ./sleep_batch.sh\n",
    "!flux batch --nslots=2 --cores-per-slot=1 --nodes=2 ./sleep_batch.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da98bfa1",
   "metadata": {},
   "source": [
    "The contents of `sleep_batch.sh`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-witch",
   "metadata": {},
   "source": [
    "``` bash \n",
    "    #!/bin/bash\n",
    "  \n",
    "    echo \"Starting my batch job\"\n",
    "    echo \"Print the resources allocated to this batch job\"\n",
    "    flux resource list\n",
    "\n",
    "    echo \"Use sleep to emulate a parallel program\"\n",
    "    echo \"Run the program at a total of 2 processes each requiring\"\n",
    "    echo \"1 core. These processes are equally spread across 2 nodes.\"\n",
    "    flux run -N 2 -n 2 sleep 30\n",
    "    flux run -N 2 -n 2 sleep 30\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edff8993-3c39-4f46-939d-4c8be5739fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are submitting a job that generates output, and asking to write it to /tmp/cheese.txt\n",
    "!flux submit --out /tmp/cheese.txt echo \"Sweet dreams üåöÔ∏è are made of cheese, who am I to diss a brie? üßÄÔ∏è\"\n",
    "\n",
    "# This will show us JOBIDs\n",
    "!flux jobs\n",
    "\n",
    "# You could copy a JOBID from above and paste it in the line below to examine the job's resources and output\n",
    "# or get the last jobid with \"flux job last\" (this is what we will do here)\n",
    "# JOBID=\"∆íFoRYVpt7\"\n",
    "\n",
    "# Note here we are using flux job last to see the last one\n",
    "# The \"R\" here asks for the resource spec\n",
    "!flux job info $(flux job last) R\n",
    "\n",
    "# When we attach it will direct us to our output file\n",
    "!flux job attach $(flux job last)\n",
    "\n",
    "# And we can look at the output file to see our expected output!\n",
    "!cat /tmp/cheese.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e525e2-6c89-4c14-9fae-d87a0d4fc574",
   "metadata": {},
   "source": [
    "To list all completed jobs, run `flux jobs -a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8a8b7c-f475-4a51-8bc6-9983dc9d78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e415ecc-f451-4909-a2bf-351a639cd7fa",
   "metadata": {},
   "source": [
    "To restrict the output to failed (i.e., jobs that exit with nonzero exit code, time out, or are canceled or killed) jobs, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032597d2-4b02-47ea-a5e5-915313cdd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs -f failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2ae62-3e3b-4c82-a0c7-4c97ff1376d2",
   "metadata": {},
   "source": [
    "# Flux Process and Job Utilities\n",
    "## Flux top\n",
    "Flux provides a feature-full version of `top` for nested Flux instances and jobs. In the JupyterLab terminal, invoke `flux top` to see the \"sleep\" jobs. If they have already completed you can resubmit them. \n",
    "\n",
    "We recommend not running `flux top` in the notebook as it is not designed to display output from a command that runs continuously.\n",
    "\n",
    "## Flux pstree\n",
    "In analogy to `top`, Flux provides `flux pstree`. Try it out in the JupyterLab terminal or here in the notebook.\n",
    "\n",
    "## Flux proxy\n",
    "### Interacting with a job hierarchy with `flux proxy`\n",
    "#### Example 1\n",
    "Routes messages to and from a Flux instance. We can use `flux proxy` to connect to a running Flux instance and then submit more nested jobs inside it. You may want to edit `sleep_batch.sh` with the JupyterLab text editor (double click the file in the window on the left) to sleep for `60` or `120` seconds. Then from the JupyterLab terminal, run: \n",
    "\n",
    "`flux batch --nslots=2 --cores-per-slot=1 --nodes=2 ./sleep_batch.sh` # outputs JOBID\n",
    "\n",
    "`flux pstree -x`\n",
    "\n",
    "`flux proxy JOBID` # this connects you to the Flux instance corresponding to JOBID above\n",
    "\n",
    "`flux uptime` # Note the depth is now 1 and the size is 2: we're one level deeper in a Flux hierarchy and we have only 2 brokers now.\n",
    "\n",
    "`flux resource list` # This instance has 2 \"nodes\" and 2 cores allocated to it\n",
    "\n",
    "`flux top`\n",
    "\n",
    "#### Example 2\n",
    "Contents of `sleeps.sh`:\n",
    "\n",
    "``` bash \n",
    "#!/bin/bash\n",
    "\n",
    "flux submit -N1 sleep 30\n",
    "flux submit -N1 sleep 30\n",
    "flux submit -N1 sleep 30\n",
    "flux submit -N1 sleep 30\n",
    "flux queue drain\n",
    "```\n",
    "Note `flux queue drain` which waits for the sub-jobs to complete.\n",
    "`flux batch -N2 sleeps.sh`\n",
    "(copy output JOBID)\n",
    "`flux proxy JOBID`\n",
    "`flux jobs`\n",
    "\n",
    "#### Example 3\n",
    "Here's an example of submitting jubs within a nested instance. You can run this example here in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6976f8-dbb6-405e-a06b-47c571aa1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat sub_job1.sh\n",
    "!cat sub_job2.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8640a611-38e4-42b1-a913-89e0c76c8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux batch -N1 ./sub_job1.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b7ffcb",
   "metadata": {},
   "source": [
    "Here is how to try flux pstree, which normally can show jobs in an instance, but it has limited functionality given we are in a notebook! So instead of just running the single command, let's add \"-a\" to indicate \"show me ALL jobs.\"\n",
    "More complex jobs and in a different environment would have deeper nesting. You can [see examples here](https://flux-framework.readthedocs.io/en/latest/jobs/hierarchies.html?h=pstree#flux-pstree-command).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2b1f0b-e6c2-4583-8068-7c76fa341884",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux pstree -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997faffc",
   "metadata": {},
   "source": [
    "## Submission API\n",
    "Flux also provides first-class python bindings which can be used to submit jobs programmatically. The following script shows this with the `flux.job.submit()` call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import flux\n",
    "from flux.job import JobspecV1\n",
    "from flux.job.JobID import JobID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = flux.Flux() # connect to the running Flux instance\n",
    "compute_jobreq = JobspecV1.from_command(\n",
    "    command=[\"./compute.py\", \"120\"], num_tasks=1, num_nodes=1, cores_per_task=1\n",
    ") # construct a jobspec\n",
    "compute_jobreq.cwd = os.path.expanduser(\"..//flux-workflow-examples/job-submit-api/\") # set the CWD\n",
    "print(JobID(flux.job.submit(f,compute_jobreq)).f58) # submit and print out the jobid (in f58 format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d679897-7054-4f96-b340-7f39245aca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs -a | grep compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d332f9c9",
   "metadata": {},
   "source": [
    "Under the hood, the `Jobspec` class is creating a YAML document that ultimately gets serialized as JSON and sent to Flux for ingestion, validation, queueing, scheduling, and eventually execution.  We can dump the raw JSON jobspec that is submitted, where we can see the exact resources requested and the task set to be executed on those resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa06478",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_jobreq.dumps(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bbc90e",
   "metadata": {},
   "source": [
    "We can then replicate our previous example of submitting multiple heterogeneous jobs and testing that Flux co-schedules them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_jobreq = JobspecV1.from_command(\n",
    "    command=[\"./compute.py\", \"120\"], num_tasks=4, num_nodes=2, cores_per_task=2\n",
    ")\n",
    "compute_jobreq.cwd = os.path.expanduser(\"../flux-workflow-examples/job-submit-api/\")\n",
    "print(JobID(flux.job.submit(f, compute_jobreq)))\n",
    "\n",
    "io_jobreq = JobspecV1.from_command(\n",
    "    command=[\"./io-forwarding.py\", \"120\"], num_tasks=1, num_nodes=1, cores_per_task=1\n",
    ")\n",
    "io_jobreq.cwd = os.path.expanduser(\"../flux-workflow-examples/job-submit-api/\")\n",
    "print(JobID(flux.job.submit(f, io_jobreq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux jobs -a | grep compute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8051640",
   "metadata": {},
   "source": [
    "We can use the FluxExecutor class to submit large numbers of jobs to Flux. This method uses python's `concurrent.futures` interface.  Example snippet from `~/flux-workflow-examples/async-bulk-job-submit/bulksubmit_executor.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-trace",
   "metadata": {},
   "source": [
    "``` python \n",
    "with FluxExecutor() as executor:\n",
    "        compute_jobspec = JobspecV1.from_command(args.command)\n",
    "        futures = [executor.submit(compute_jobspec) for _ in range(args.njobs)]\n",
    "        # wait for the jobid for each job, as a proxy for the job being submitted\n",
    "        for fut in futures:\n",
    "            fut.jobid()\n",
    "        # all jobs submitted - print timings\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit a FluxExecutor based script.\n",
    "%run ../flux-workflow-examples/async-bulk-job-submit/bulksubmit_executor.py -n200 /bin/sleep 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec052119",
   "metadata": {},
   "source": [
    "# Diving Deeper Into Flux's Internals\n",
    "\n",
    "Flux uses [hwloc](https://github.com/open-mpi/hwloc) to detect the resources on each node and then to populate its resource graph.\n",
    "\n",
    "You can access the topology information that Flux collects with the `flux resource` subcommand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux resource list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0086e47e",
   "metadata": {},
   "source": [
    "Flux can also bootstrap its resource graph based on static input files, like in the case of a multi-user system instance setup by site administrators.  [More information on Flux's static resource configuration files](https://flux-framework.readthedocs.io/en/latest/adminguide.html#resource-configuration).  Flux provides a more standard interface to listing available resources that works regardless of the resource input source: `flux resource`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To view status of resources\n",
    "!flux resource status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee1c49d",
   "metadata": {},
   "source": [
    "Flux has a command for controlling the queue within the `job-manager`: `flux queue`.  This includes disabling job submission, re-enabling it, waiting for the queue to become idle or empty, and checking the queue status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800de4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux queue disable \"maintenance outage\"\n",
    "!flux queue enable\n",
    "!flux queue -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aa7559",
   "metadata": {},
   "source": [
    "Each Flux instance has a set of attributes that are set at startup that affect the operation of Flux, such as `rank`, `size`, and `local-uri` (the Unix socket usable for communicating with Flux).  Many of these attributes can be modified at runtime, such as `log-stderr-level` (1 logs only critical messages to stderr while 7 logs everything, including debug messages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux getattr rank\n",
    "!flux getattr size\n",
    "!flux getattr local-uri\n",
    "!flux setattr log-stderr-level 3\n",
    "!flux lsattr -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74fdfcf",
   "metadata": {},
   "source": [
    "Services within a Flux instance are implemented by modules. To query and manage broker modules, use `flux module`.  Modules that we have already directly interacted with in this tutorial include `resource` (via `flux resource`), `job-ingest` (via `flux` and the Python API) `job-list` (via `flux jobs`) and `job-manager` (via `flux queue`), and we will interact with the `kvs` module in a few cells. For the most part, services are implemented by modules of the same name (e.g., `kvs` implements the `kvs` service and thus the `kvs.lookup` RPC).  In some circumstances, where multiple implementations for a service exist, a module of a different name implements a given service (e.g., in this instance, `sched-fluxion-qmanager` provides the `sched` service and thus `sched.alloc`, but in another instance `sched-simple` might provide the `sched` service)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux module list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7090eb",
   "metadata": {},
   "source": [
    "We can actually unload the Fluxion modules (the scheduler modules from flux-sched) and replace them with `sched-simple` (the scheduler that comes built-into flux-core) as a demonstration of this functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4bc2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux module unload sched-fluxion-qmanager\n",
    "!flux module unload sched-fluxion-resource\n",
    "!flux module load sched-simple\n",
    "!flux module list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722c4ecf",
   "metadata": {},
   "source": [
    "We can now reload the Fluxion scheduler, but this time, let's pass some extra arguments to specialize our Flux instance.  In particular, let's populate our resource graph with nodes, sockets, and cores and limit the scheduling depth to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34899ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux dmesg -C\n",
    "!flux module unload sched-simple\n",
    "!flux module load sched-fluxion-resource load-allowlist=node,socket,core\n",
    "!flux module load sched-fluxion-qmanager queue-params=queue-depth=4\n",
    "!flux module list\n",
    "!flux dmesg | grep queue-depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4b0e04",
   "metadata": {},
   "source": [
    "The key-value store (KVS) is a core component of a Flux instance. The `flux kvs` command provides a utility to list and manipulate values of the KVS. Modules of Flux use the KVS to persistently store information and retrieve it later on (potentially after a restart of Flux).  One example of KVS use by Flux is the `resource` module, which stores the resource set `R` of the current Flux instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux kvs ls \n",
    "!flux kvs ls resource\n",
    "!flux kvs get resource.R | jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3920f9e",
   "metadata": {},
   "source": [
    "Flux provides a built-in mechanism for executing commands on nodes without requiring a job or resource allocation: `flux exec`.  `flux exec` is typically used by sys admins to execute administrative commands and load/unload modules across multiple ranks simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9507c7b-de5c-4129-9a99-c943614a9ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux exec -r 2 flux getattr rank # only execute on rank 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9de119-abc4-4917-a339-2010ccc7b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!flux exec flux getattr rank # execute on all ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3e767-0459-4218-a8cf-0f98bd32d6bf",
   "metadata": {},
   "source": [
    "# This concludes the notebook tutorial. üò≠Ô∏èüòÑÔ∏è\n",
    "\n",
    "Don't worry, you'll have more opportunities for using Flux! We hope you reach out to us on any of our [project repositories](https://flux-framework.org) and ask any questions that you have. We'd love your contribution to code, documentation, or just saying hello! üëãÔ∏è If you have feedback on the tutorial, please let us know so we can improve it for next year. \n",
    "\n",
    "> But what do I do now?\n",
    "\n",
    "Feel free to experiment more with Flux here, or (for more freedom) in the terminal. You can try more of the examples in the flux-workflow-examples directory one level up in the window to the left. If you're using a shared system like the one on the RADIUSS AWS tutorial please be mindful of other users and don't run compute intensive workloads. If you're running the tutorial in a job on an HPC cluster... compute away! ‚öæÔ∏è\n",
    "\n",
    "> Where can I learn to set this up on my own?\n",
    "\n",
    "If you're interested in installing Flux on your cluster, take a look at the [system instance instructions](https://flux-framework.readthedocs.io/en/latest/adminguide.html). If you are interested in running Flux on Kubernetes, check out the [Flux Operator](https://github.com/flux-framework/flux-operator). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82657547-fc4a-459c-b628-3a60fea84c8d",
   "metadata": {},
   "source": [
    "![https://flux-framework.org/flux-operator/_static/images/flux-operator.png](https://flux-framework.org/flux-operator/_static/images/flux-operator.png)\n",
    "\n",
    "> See you next year! üëãÔ∏èüòéÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5679d1-742f-4e10-8edf-8dce96415da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
